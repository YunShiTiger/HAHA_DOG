# kubernetes + server mesh

## 基本操作

### 关闭防火墙

```
systemctl disable firewalld
```

验证

```
service firewalld status
打印出dead为成功
```

### 关闭selinux

```
vi /etc/selinux/config
```

```
将SELINUX=enforcing 改为SELINUX=disabled
```

验证

```
getenforce
打印出disabled为修改成功
```

### 关闭交换空间

```
vi /etc/fstab
```

```
注释swap项
```

### 修改节点名

```
vi /etc/hostname
```

```
修改为节点名
```

### 将节点IP加入到hosts中

查看IP

```
ifconfig
```

我的节点IP为

192.168.136.181---master    192.168.136.176---node-1  192.168.136.176---node-2

```
vi /etc/hosts
```

加入地址

```
192.168.136.181 master
192.168.136.176 node-1
192.168.136.176 node-2
```

### 配置系统内核参数使流过网桥的流量

```
vi /etc/sysctl.conf
```

添加

```
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
```

### 配置阿里源

```
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0 
EOF
```



## ##重启##

```
reboot
```



## 安装Docker

### 卸载旧版本

```
yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```

### 安装相关组件

```
yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
```

### 配置yum源

```
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
```

### 安装

```
yum install docker-ce docker-ce-cli containerd.io -y
```

### 设置启动项

```
systemctl enable docker
```

### 配置docker阿里源加速器

```
mkdir -p /etc/docker
```

```
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://tsqluof3.mirror.aliyuncs.com"]
}
EOF
```

```
systemctl daemon-reload
```

```
systemctl restart docker
```

## 安装kubernetes

### 安装组件

```
yum -y install kubelet kubeadm kubectl
```

```
systemctl enable kubelet
```

### 镜像

#### 查看该版本镜像

```
kubeadm config images list
```

输出

```
k8s.gcr.io/kube-apiserver:v1.13.4
k8s.gcr.io/kube-controller-manager:v1.13.4
k8s.gcr.io/kube-scheduler:v1.13.4
k8s.gcr.io/kube-proxy:v1.13.4
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.2.24
k8s.gcr.io/coredns:1.2.6
```

#### 镜像拉取脚本

```
echo ""
echo "=========================================================="
echo "Pull Kubernetes v1.13.3 Images from aliyuncs.com ......"
echo "=========================================================="
echo ""

MY_REGISTRY=registry.cn-hangzhou.aliyuncs.com/openthings

## 拉取镜像
docker pull ${MY_REGISTRY}/k8s-gcr-io-kube-apiserver:v1.13.3
docker pull ${MY_REGISTRY}/k8s-gcr-io-kube-controller-manager:v1.13.3
docker pull ${MY_REGISTRY}/k8s-gcr-io-kube-scheduler:v1.13.3
docker pull ${MY_REGISTRY}/k8s-gcr-io-kube-proxy:v1.13.3
docker pull ${MY_REGISTRY}/k8s-gcr-io-etcd:3.2.24
docker pull ${MY_REGISTRY}/k8s-gcr-io-pause:3.1
docker pull ${MY_REGISTRY}/k8s-gcr-io-coredns:1.2.6


## 添加Tag
docker tag ${MY_REGISTRY}/k8s-gcr-io-kube-apiserver:v1.13.3 k8s.gcr.io/kube-apiserver:v1.13.3
docker tag ${MY_REGISTRY}/k8s-gcr-io-kube-scheduler:v1.13.3 k8s.gcr.io/kube-scheduler:v1.13.3
docker tag ${MY_REGISTRY}/k8s-gcr-io-kube-controller-manager:v1.13.3 k8s.gcr.io/kube-controller-manager:v1.13.3
docker tag ${MY_REGISTRY}/k8s-gcr-io-kube-proxy:v1.13.3 k8s.gcr.io/kube-proxy:v1.13.3
docker tag ${MY_REGISTRY}/k8s-gcr-io-etcd:3.2.24 k8s.gcr.io/etcd:3.2.24
docker tag ${MY_REGISTRY}/k8s-gcr-io-pause:3.1 k8s.gcr.io/pause:3.1
docker tag ${MY_REGISTRY}/k8s-gcr-io-coredns:1.2.6 k8s.gcr.io/coredns:1.2.6

echo ""
echo "=========================================================="
echo "Pull Kubernetes v1.13.3 Images FINISHED."
echo "into registry.cn-hangzhou.aliyuncs.com/openthings, "
echo "           by openthings@https://my.oschina.net/u/2306127."
echo "=========================================================="

echo ""
```

### 创建集群

#### 主节点

```
kubeadm init --kubernetes-version=v1.13.3 --apiserver-advertise-address=192.168.159.169 --pod-network-cidr=192.168.0.0/16
```

#### 从节点

```
kubeadm join 192.168.159.169:6443 --token qjrofm.nercx1owut5s5t7z --discovery-token-ca-cert-hash sha256:e20dff74fbfa25339ef64511fd8bb0b4acca0b3000a53bf16ee19c319c207a4d
```

#### 配置命令行

```
echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bash_profile
```

或

```
export KUBECONFIG=/etc/kubernetes/admin.conf
```

```
source ~/.bash_profile
```

#### 安装calico

```
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml
```

```
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml
```

#### CoreDNS无限重启(查看网卡配置或执行下面)

```
kubectl -n kube-system get deployment coredns -o yaml | \
  sed 's/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g' | \
  kubectl apply -f -
```

```
reboot
```

#### 可选:主节点加入工作

```
kubectl taint nodes --all node-role.kubernetes.io/master-
```

输出

```\
node/k8s-m untainted
error: taint "node-role.kubernetes.io/master:" not found
```

#### 注:从节点token过期后加入集群

##### 查看token

```
kubeadm token list
```

##### 生成token

```
kubeadm token create
```

打印

```
5didvk.d09sbcov8ph2amjw
```

##### 获取token

```
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \
   openssl dgst -sha256 -hex | sed 's/^.* //'
```

打印

```
8cb2de97839780a412b93877f8507ad6c94f73add17d5d7058e91741c9d5ec78
```

## 安装DashBoard

### 镜像准备

```
docker pull registry.cn-beijing.aliyuncs.com/minminmsn/kubernetes-dashboard:v1.10.1
```

```
docker tag registry.cn-beijing.aliyuncs.com/minminmsn/kubernetes-dashboard:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
```

```
docker rmi registry.cn-beijing.aliyuncs.com/minminmsn/kubernetes-dashboard:v1.10.1
```

### 证书生成

#### 生成

```
mkdir certs
```

```
openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048
```

```
openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.key
```

```
rm dashboard.pass.key
```

```
openssl req -new -key dashboard.key -out dashboard.csr
```

反馈输入:

```
...
Country Name (2 letter code) [AU]: US
...
A challenge password []:
...
```

#### 密钥生成

```
openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt
```

#### 检查

```
ls certs
```

#### 创建

```
kubectl create secret generic kubernetes-dashboard-certs --from-file=certs -n kube-system
```

### 获取dashboard.yaml

```
wget https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml
```

注:修改service为NodePort访问

#### 部署

```
kubectl create -f kubernetes-dashboard.yaml 
```

#### 配置dashboard-admin.yaml

```
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: admin
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: admin
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin
  namespace: kube-system
  labels:
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
```

```
kubectl apply -f dashboard-admin.yaml
```

### Token获取

```
kubectl describe secret/$(kubectl get secret -nkube-system |grep admin|awk '{print $1}') -n kube-system
```

### 访问

```
https://192.168.240.59
```

选择token进入

## 卸载kubernetes

```
kubectl drain <node name> --delete-local-data --force --ignore-daemonsets
```

```
kubectl delete node <node name>
```

```
kubeadm reset
```

```
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
```

```
ipvsadm -C
```

## 安装Helm

### helm

```
tar -zxvf helm-v2.13.0-linux-amd64.tar.gz
```

```
mv linux-amd64/helm /usr/local/bin/helm
```

测试

```
helm help
```

### tiller

安装tiller到群集中的最简单方法就是运行

```
helm init
```

安装成功后在kubernetes的pods中查看tiller已为running

使用阿里源:

```
helm init -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.0 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
```

### 查看版本

```
helm version
```

打印

```
Client: &version.Version{SemVer:"v2.13.0", GitCommit:"79d07943b03aea2b76c12644b4b54733bc5958d6", GitTreeState:"clean"}
Server: &version.Version{SemVer:"v2.13.0", GitCommit:"79d07943b03aea2b76c12644b4b54733bc5958d6", GitTreeState:"clean"}
```

### 添加服务目录到Helm存储库

```
helm repo add svc-cat https://svc-catalog-charts.storage.googleapis.com
helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
```

打印

```
"svc-cat" has been added to your repositories
```

### 查看服务

```
helm search service-catalog
```

打印

```
NAME           	CHART VERSION	APP VERSION	DESCRIPTION              
svc-cat/catalog	0.1.42       	           	service-catalog API server and controller-manager helm chart
```

### 启用RBAC

```
kubectl create clusterrolebinding tiller-cluster-admin \
    --clusterrole=cluster-admin \
    --serviceaccount=kube-system:default
```

打印

```
clusterrolebinding.rbac.authorization.k8s.io/tiller-cluster-admin created
```

### 更新helm repo

```
helm repo update
```

### 版本倾斜

#### 方式一:直接升级

```
helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.0 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
```

#### 方式二:直接升级后找不到tiller

##### 描述

```
查看pods看不到tiller，helm init --upgrade 显示成功但是依旧看不到tiller
```

##### ※查看方式

```
kubectl get all --all-namespaces | grep tiller 
```

打印

```
kube-system        service/tiller-deploy                                        ClusterIP   10.108.20.231    <none>        44134/TCP                    22d




kube-system        deployment.apps/tiller-deploy                         0/1     0            0           22d
kube-system        replicaset.apps/tiller-deploy-57b94f8755                       0         0         0       21m
kube-system        replicaset.apps/tiller-deploy-5b7c66d59c                       0         0         0       26m
kube-system        replicaset.apps/tiller-deploy-6c89564b                         1         0         0       14m
kube-system        replicaset.apps/tiller-deploy-6d6cc8dcb5                       0         0         0       22d
kube-system        replicaset.apps/tiller-deploy-789c985cfb                       0         0         0       21m
kube-system        replicaset.apps/tiller-deploy-7974d47f54                       0         0         0       7m43s
kube-system        replicaset.apps/tiller-deploy-7bf99c9559                       0         0         0       9d
```

##### 删除tiller

```
kubectl get -n kube-system secrets,sa,clusterrolebinding -o name|grep tiller|xargs kubectl -n kube-system delete
```

```
kubectl get all -n kube-system -l app=helm -o name|xargs kubectl delete -n kube-system
```

打印

```
service "tiller-deploy" deleted
deployment.apps "tiller-deploy" deleted
replicaset.apps "tiller-deploy-57b94f8755" deleted
Error from server (NotFound): replicasets.apps "tiller-deploy-5b7c66d59c" not found
Error from server (NotFound): replicasets.apps "tiller-deploy-6c89564b" not found
Error from server (NotFound): replicasets.apps "tiller-deploy-6d6cc8dcb5" not found
Error from server (NotFound): replicasets.apps "tiller-deploy-789c985cfb" not found
Error from server (NotFound): replicasets.apps "tiller-deploy-7974d47f54" not found
Error from server (NotFound): replicasets.apps "tiller-deploy-7bf99c9559" not found
```

##### 重新安装tiller

```
helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.0 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
```

```
kubectl create clusterrolebinding tiller-cluster-admin \
    --clusterrole=cluster-admin \
    --serviceaccount=kube-system:default
```

#### 参考

```
https://www.cnblogs.com/jackluo/p/10345266.html
```



## Ingress

### traefik

#### 授权

```
kubectl apply -f traefik-rbac.yaml
```

#### 创建configmap

```
kubectl create configmap traefik-conf --from-file=traefik.toml -n kube-system
```

#### 部署ingress-controller + service

```
kubectl apply -f traefik-deployment.yaml
```

#### 配置证书

##### 运营商

```
kubectl create secret generic qwe --from-file=2017585_www.xjlhcz.com.key --from-file=2017585_www.xjlhcz.com.pem -n kube-system
```

```
kubectl create secret generic gogen.cn --from-file=1592339__gogen.cn.pem --from-file=1592339__gogen.cn.key -n kube-system
```

##### 服务器生成

```
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj "/CN=www.xjlhcz.com"
```

```
kubectl -n kube-system create secret tls qwe --key=tls.key --cert=tls.crt
```

#### 注入ui界面的ingress及service

```
kubectl apply -f ui.yaml
```

或者ingress.yaml

#### 参考:

```
https://docs.traefik.io/user-guide/kubernetes/
```

↑翻墙

```
https://blog.51cto.com/devingeng/2153778
```

↑不翻墙

### nginx

#### 部署ingress-controller

```
kubectl apply -f ingress-controller.yaml 
```

#### 部署ingress-controller-service

```
kubectl apply -f ingress-controller-service.yaml 
```

#### 验证

```
kubectl get pods --all-namespaces -l app.kubernetes.io/name=ingress-nginx --watch
```

#### 配置证书

```
kubectl create secret tls yzb --key 2017585_www.xjlhcz.com.key --cert 2017585_www.xjlhcz.com.pem
```

#### 注入ingress

```
kubectl apply -f map.yaml
```

或者ingress.yaml

#### 页面访问



## 安装Istio(Service Mesh)

可选下载最新版

```
curl -L https://git.io/getLatestIstio | sh -
```

### 进入istio目录

```
cd istio-1.0.6
```

#### 添加到PATH环境变量

```
export PATH=$PWD/bin:$PATH
```

### 安装

```
kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml
```

```
kubectl apply -f install/kubernetes/helm/istio/charts/certmanager/templates/crds.yaml
```

#### 安装方式①

使用Helm via安装 helm template

##### 将Istio的核心组件渲染为Kubernetes清单，称为istio.yaml：

```
helm template install/kubernetes/helm/istio --name istio --namespace istio-system > $HOME/istio.yaml
```

###### 通过清单安装组件：

```
kubectl create namespace istio-system
```

```
kubectl apply -f $HOME/istio.yaml
```

#### 安装方式②

此选项允许Helm和 Tiller 管理Istio的生命周期。

##### 如果尚未为Tiller安装服务帐户，先进行创建：

```
kubectl apply -f install/kubernetes/helm/helm-service-account.yaml
```

##### 使用服务帐户在群集上安装Tiller

```
helm init --service-account tiller
```

##### 安装Istio

```
helm install install/kubernetes/helm/istio --name istio --namespace istio-system
```

### 卸载

##### 方式①

```
kubectl delete -f $HOME/istio.yaml
```

##### 方式②

```
helm delete --purge istio
```

##### Helm版本低于2.9进行job清除

```
kubectl -n istio-system delete job --all
```

##### 删除CRD

```
kubectl delete -f install/kubernetes/helm/istio/templates/crds.yaml -n istio-system
```





```
helm template install/kubernetes/helm/istio --set global.mtls.enabled=false --set tracing.enabled=true --set kiali.enabled=true --set grafana.enabled=true --namespace istio-system > istio.yaml
```

### 实施方案(类似安装方式①)

#### 更新 Helm 的本地包缓存 

```
helm repo add istio.io "https://gcsweb.istio.io/gcs/istio-prerelease/daily-build/release-1.1-latest-daily/charts/"
```

#### 创建istio工作目录

创建一个 Istio 的工作目录，用于下载 Chart:

```
mkdir -p $HOME/istio-fetch
```

#### 下载安装过程所需的 Helm 模板 

```
helm fetch istio.io/istio-init --untar --untardir $HOME/istio-fetch
```

```
helm fetch istio.io/istio --untar --untardir $HOME/istio-fetch
```

#### 创建命名空间

```
kubectl create namespace istio-system
```

#### 渲染

```
helm template $HOME/istio-fetch/istio-init --name istio-init --namespace istio-system | kubectl apply -f -
```

#### 查看grd

```
kubectl get crds | grep 'istio.io\|certmanager.k8s.io' | wc -l
打印:"58"
```

#### 创建

```
helm template $HOME/istio-fetch/istio --name istio --namespace istio-system | kubectl apply -f -
```







